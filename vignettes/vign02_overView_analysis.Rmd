title: "adverSCarial, generate and analyze the vulnerability of scRNA-seq
    classifiers to adversarial attacks"
shorttitle: "adverSCarial"
author: Ghislain FIEVET <ghislain.fievet@gmail.com>
package: adverSCarial
abstract: >
    adverSCarial is an R Package designed for generating and analyzing the vulnerability of scRNA-seq
    classifiers to adversarial attacks. The package is versatile and provides a format for integrating
    any type of classifier. It offers functions for studying and generating two types of attacks,
    min change attack and max change attack. The min change attack involves making a small modification
    to the input to alter the classification. The max change attack involves making a large modification
    to the input without changing its classification.
    The package provides a comprehensive solution for evaluating the robustness of scRNA-seq classifiers
    against adversarial attacks.
vignette: >
  %\VignetteIndexEntry{Vign02_overView_analysis}
  %\VignetteEngine{knitr::knitr}
  %\VignetteEncoding{UTF-8}

# Load data
  
```{r load libraries, warning = FALSE, message=FALSE}
library(adverSCarial)
library(LoomExperiment)
```

## Load loom file
```{r min change attack, message=FALSE, warning = FALSE}
pbmcPath <- system.file("extdata", "pbmc_short.loom", package="adverSCarial")
lfile <- import(pbmcPath, type="SingleCellLoomExperiment")
```

```{r load table}
matPbmc <- as.data.frame(counts(lfile))
```

```{r visualize1, message=FALSE, warning = FALSE}
matPbmc[1:5,1:5]
```
## Load cell type annotations
```{r Load cell type annotations, message=FALSE, warning = FALSE}
cellTypes <- rowData(lfile)$cell_type
```

```{r visualize2, message=FALSE, warning = FALSE}
head(cellTypes)
```

# Run vulnerability analysis with `minChangeOverview` and `maxChangeOverview`

The `minChangeOverview` and `maxChangeOverview` functions are designed to provide insight into of the min and max change adversarial attacks on each cell type, on various gene modifications.

## Which attack to choose?
Before generating an attack it is judicious to choose the cell type to attack, and the modification susceptible to lead to a successful attack. Both functions run attack approximations, faster than the original, by studying splices of 100 genes.

## Which classifier is more vulnerable to adversarial attacks?
Sometimes we want to compare two classifiers and see which one is more vulnerable to adversarial attacks.


## Which modifications to compare

Here we define the modifications to analyse, the predefined `perc1`, and a custom function returning high outliers called `modifOutlier`.
```{r modifications for overview, warning = FALSE}
modifOutlier <- function(x){
    return (max(x)*1000)
}

```{r use the function, warning = FALSE}
modifications <- list(c("perc1"), c("full_row_fct", modifOutlier))
```

We run the `min change overview`, this gives us a general idea of which cell types are more vulnerable to min change attacks.
```{r run min change overview, warning = FALSE, message=FALSE}
min_change_overview <- minChangeOverview(matPbmc, cellTypes, MClassifier, modifications= modifications, maxSplitSize = 20, firstDichot = 5)
```
```{r run min change overview bis, warning = FALSE}
min_change_overview
```

And the `max change overview`, giving us a general idea of which cell types are more vulnerable to max change attacks.
```{r run max change overview, warning = FALSE, cache = TRUE, message=FALSE}
max_change_overview <- maxChangeOverview(matPbmc, cellTypes, MClassifier, modifications= modifications, maxSplitSize = 20)
```
```{r run max change overview bis, warning = FALSE}
max_change_overview
```

```{r session info}
sessionInfo()
```
